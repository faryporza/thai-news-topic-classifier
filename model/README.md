# üáπüá≠ Thai News Topic Classifier - Model Training

‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡πà‡∏≤‡∏ß‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (Thai News Topic Classification)

---

## üöÄ Model Options

| Model | Script | Accuracy | Speed | Status |
|-------|--------|----------|-------|--------|
| **WangchanBERTa** (‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á) | `train_wangchanberta.py` | **100%** ‚úÖ | ‚ö†Ô∏è ‡∏ä‡πâ‡∏≤ (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ GPU) | üü¢ Active |
| TF-IDF + Logistic Regression | `train_model.py` | ~85-90% | ‚úÖ ‡πÄ‡∏£‡πá‡∏ß | üî¥ Deprecated |

> **‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏• WangchanBERTa ‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100% ‡∏ö‡∏ô Test Set (900 samples)**

---

## üèÜ ‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏≤‡πÉ‡∏ä‡πâ WangchanBERTa?

### ‚ùå ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á TF-IDF + Logistic Regression

| ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á |
|-------|----------|----------|
| **‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó** | ‡∏°‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¥‡∏™‡∏£‡∏∞ ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏´‡∏ô | ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏ï‡∏•‡∏≤‡∏î" ‡πÉ‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏∏‡πâ‡∏ô vs ‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡∏ñ‡∏π‡∏Å‡∏°‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô |
| **Mixed Signal** | ‡∏™‡∏±‡∏ö‡∏™‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πà‡∏≤‡∏ß‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô | ‡∏Ç‡πà‡∏≤‡∏ß Business ‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á AI ‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô SciTech |
| **‡πÑ‡∏°‡πà‡∏ó‡∏ô Typo** | ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏Å‡∏î‡∏ú‡∏¥‡∏î‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å | "‡πÄ‡∏ó‡∏ï‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ" ‚Üí ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å |
| **OOV Problem** | ‡∏Ñ‡∏≥‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô‡∏ï‡∏≠‡∏ô training ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏∞‡πÄ‡∏•‡∏¢ | - |

### ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á WangchanBERTa

| ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥ | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|----------|----------|
| **Contextual Understanding** | ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó - ‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô |
| **Pre-trained Knowledge** | ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å corpus ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß |
| **Subword Tokenization** | ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡πÄ‡∏õ‡πá‡∏ô subword ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ |
| **Robust to Noise** | ‡∏ó‡∏ô‡∏ï‡πà‡∏≠ typo ‡πÅ‡∏•‡∏∞ noise ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ |

### üìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö

```
‡∏Ç‡πà‡∏≤‡∏ß: "‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô‡∏õ‡∏¥‡∏î‡∏ö‡∏ß‡∏Å 15 ‡∏à‡∏∏‡∏î ‡∏ó‡πà‡∏≤‡∏°‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI"

TF-IDF:
- ‡∏û‡∏ö‡∏Ñ‡∏≥ "‡∏ï‡∏•‡∏≤‡∏î", "‡∏´‡∏∏‡πâ‡∏ô" ‚Üí ‡∏ô‡πà‡∏≤‡∏à‡∏∞ Business
- ‡∏û‡∏ö‡∏Ñ‡∏≥ "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ", "AI" ‚Üí ‡∏ô‡πà‡∏≤‡∏à‡∏∞ SciTech
- ‚ùå ‡∏™‡∏±‡∏ö‡∏™‡∏ô! ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£

WangchanBERTa:
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤ "‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô" ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å
- "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI" ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö
- ‚úÖ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Business
```

---

## üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Dataset

- **‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: ‡∏Ç‡πà‡∏≤‡∏ß‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (Thai News Topic Dataset)
- **Input Features**: `headline` (‡∏û‡∏≤‡∏î‡∏´‡∏±‡∏ß) + `body` (‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß)
- **Target Label**: `topic` (SciTech, World, Business)
- **‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: train_easy, version clean
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô samples**: ~4,500

---

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô

### Option 1: WangchanBERTa (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á)

#### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment

```bash
cd model
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
```

#### 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
pip install -r requirements_bert.txt
```

#### 3. ‡∏£‡∏±‡∏ô Training

```bash
python train_wangchanberta.py
```

> ‚ö†Ô∏è **Note**: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ GPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö CUDA ‡πÅ‡∏•‡∏∞ Apple Silicon MPS)

---

### Option 2: TF-IDF + Logistic Regression (Baseline - ‡πÄ‡∏£‡πá‡∏ß)

```bash
cd model
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python train_model.py
```

---

## üìÅ Output Files

### WangchanBERTa (`output_bert/`)
```
output_bert/
‚îú‚îÄ‚îÄ wangchanberta_model/       # Trained model directory
‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îú‚îÄ‚îÄ model.safetensors
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_config.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ confusion_matrix_bert.png  # Confusion matrix
‚îî‚îÄ‚îÄ logs/                      # Training logs
```

### TF-IDF (`output/`)
```
output/
‚îú‚îÄ‚îÄ tfidf_vectorizer.joblib
‚îú‚îÄ‚îÄ logistic_regression_model.joblib
‚îú‚îÄ‚îÄ confusion_matrix.png
‚îî‚îÄ‚îÄ misclassified_samples.csv
```

---

## üìä ‡∏Å‡∏≤‡∏£ Deploy / ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

### WangchanBERTa

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
model_path = "output_bert/wangchanberta_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

def predict_topic(headline: str, body: str) -> dict:
    text = headline + ' ' + body
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)
    
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)[0]
        predicted_id = torch.argmax(probs).item()
    
    return {
        "label": model.config.id2label[predicted_id],
        "confidence": probs[predicted_id].item(),
        "probabilities": {
            model.config.id2label[i]: probs[i].item() 
            for i in range(len(probs))
        }
    }

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
result = predict_topic(
    headline="‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà",
    body="‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥‡∏î‡πâ‡∏≤‡∏ô AI ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡∏£‡∏∞‡∏ö‡∏ö..."
)
print(f"Predicted: {result['label']} (confidence: {result['confidence']:.2%})")
```

### TF-IDF + Logistic Regression

```python
import joblib

vectorizer = joblib.load('output/tfidf_vectorizer.joblib')
model = joblib.load('output/logistic_regression_model.joblib')

def predict_topic(headline: str, body: str) -> str:
    text = headline + ' ' + body
    X = vectorizer.transform([text])
    return model.predict(X)[0]
```

---

## ‚öôÔ∏è Model Configuration Comparison

| Configuration | TF-IDF + LR | WangchanBERTa |
|--------------|-------------|---------------|
| **Feature Extraction** | TF-IDF (unigram + bigram) | BERT Tokenizer (Subword) |
| **Model** | Logistic Regression | Transformer (BERT) |
| **Max Features/Length** | 10,000 features | 256 tokens |
| **Parameters** | ~40K | ~110M |
| **Training Time** | ~10 seconds | ~10-30 minutes |
| **GPU Required** | ‚ùå No | ‚úÖ Recommended |

---

## üìà Actual Performance (Test Set: 900 samples)

| Model | Accuracy | Macro-F1 | Status |
|-------|----------|----------|--------|
| TF-IDF + Logistic Regression | ~85-90% | ~0.85-0.90 | Baseline |
| **WangchanBERTa** | **100%** ‚úÖ | **1.0000** | **Production** |

> üéØ **Perfect Score!** WangchanBERTa ‡∏ó‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å 900/900 samples (Business: 297, SciTech: 297, World: 306)

---

## üîß Requirements

### For WangchanBERTa (`requirements_bert.txt`)
```
torch>=2.0.0
transformers>=4.30.0
pandas
numpy
scikit-learn
matplotlib
seaborn
```

### For TF-IDF (`requirements.txt`)
```
pandas
numpy
scikit-learn
joblib
matplotlib
seaborn
```

---

## üìù Changelog

| Date | Version | Changes |
|------|---------|---------|
| 2026-01-29 | 2.0.0 | ‡πÄ‡∏û‡∏¥‡πà‡∏° WangchanBERTa model (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) |
| 2026-01-27 | 1.0.0 | Initial release with TF-IDF + Logistic Regression |
